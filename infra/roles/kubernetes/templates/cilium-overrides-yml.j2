# cilium_helm_version: {{ cilium_helm_version }}

# containerRuntime: 
#   integration: containerd
#   socketPath: ccontainerd.sock

k8sServiceHost: {{ cilium_k8s_service_host }}
k8sServicePort: 6443

securityContext:
  privileged: true
  capabilities:
    ciliumAgent:
      - CHOWN
      - KILL
      - NET_ADMIN
      - NET_RAW
      - IPC_LOCK
      - SYS_ADMIN
      - PERFMON
      - BPF      
      - SYS_RESOURCE
      - DAC_OVERRIDE
      - FOWNER
      - SETGID
      - SETUID
    cleanCiliumState:
      - NET_ADMIN
      - PERFMON
      - BPF
      - SYS_ADMIN
      - SYS_RESOURCE

cluster:
  # -- Name of the cluster. Only required for Cluster Mesh.
  name: k3s
  # -- (int) Unique ID of the cluster. Must be unique across all connected
  # clusters and in the range of 1 to 255. Only required for Cluster Mesh.
  id: 1

annotateK8sNode: true

# must have kernel 5.18 or higher
bandwidthManager:
  enabled: true
  bbr: true

# classic way of BGP in Cilium which is mutual exclusive to bgp control plane
# bgp:
#  enabled: false
#  annouce:
#    loadbalancerIP: false
#    podCIDR: false  

# New way of BGP in cilium
# bgpControlPlane:
#  enabled: true

pmtuDiscovery:
  # -- Enable path MTU discovery to send ICMP fragmentation-needed replies to
  # the client.
  enabled: true

bpf:
  # -- Allow cluster external access to ClusterIP services.
  lbExternalClusterIP: false

  # Enable native IP masquerade support in eBPF
  masquerade: true

  # -- (bool) Configure whether direct routing mode should route traffic via
  # host stack (true) or directly and more efficiently out of BPF (false) if
  # the kernel supports it. The latter has the implication that it will also
  # bypass netfilter in the host namespace.
  # @default -- `false`
  hostLegacyRouting: false

  datapathMode: netkit

# -- Clean all eBPF datapath state from the initContainer of the cilium-agent
# DaemonSet.
#
# WARNING: Use with care!
cleanBpfState: true

# -- Clean all local Cilium state from the initContainer of the cilium-agent
# DaemonSet. Implies cleanBpfState: true.
#
# WARNING: Use with care!
# cleanState: false

# -- Enables the fallback compatibility solution for when the xt_socket kernel
# module is missing and it is needed for the datapath L7 redirection to work
# properly. See documentation for details on when this can be disabled:
# https://docs.cilium.io/en/stable/operations/system_requirements/#linux-kernel.
enableXTSocketFallback: false

externalIPs:
  # -- Enable ExternalIPs service support.
  enabled: true

ipam:
  mode: "cluster-pool"
  # ciliumNodeUpdateRate: "15s"
  operator:
    # -- IPv4 CIDR list range to delegate to individual nodes for IPAM. cluster-pool-ipv4-cidr
    clusterPoolIPv4PodCIDRList: {{ cilium_cluster_pool_ipv4_pod_cidr_list }}
    # -- IPv4 CIDR mask size to delegate to individual nodes for IPAM. cluster-pool-ipv4-cidr
    clusterPoolIPv4MaskSize: {{ cilium_cluster_pool_ipv4_mask_size }}
    # -- IPv6 CIDR list range to delegate to individual nodes for IPAM. cluster-pool-ipv6-cidr
    clusterPoolIPv6PodCIDRList: {{ cilium_cluster_pool_ipv6_pod_cidr_list }}
    # -- IPv6 CIDR mask size to delegate to individual nodes for IPAM. cluster-pool-ipv6-mask-size
    clusterPoolIPv6MaskSize: {{ cilium_cluster_pool_ipv6_mask_size }}

# Only turn this on when we want to use egress gateway and have setup all the rules we need
# # -- Configure the eBPF-based ip-masq-agent
# ipMasqAgent:
#  enabled: true
#  # # the config of nonMasqueradeCIDRs
#  config:
#    nonMasqueradeCIDRs: []
#    masqLinkLocal: true
#    masqLinkLocalIPv6: false 

ipv4:
  enabled: {{ cilium_ipv4_enabled }}

ipv6:
  enabled: {{ cilium_ipv6_enabled }}

kubeProxyReplacement: "true"
kubeProxyReplacementHealthzBindAddr: "0.0.0.0:10256"

socketLB:
  hostNamespaceOnly: true

l2NeighDiscovery:
  # -- Enable L2 neighbor discovery in the agent
  enabled: true
  # -- Override the agent's default neighbor resolution refresh period.
  refreshPeriod: "30s"

enableIPv4Masquerade: true
enableIPv6Masquerade: true
# -- Enables IPv4 BIG TCP support which increases maximum IPv4 GSO/GRO limits for nodes and pods (BIG TCP is not supported in tunneling mode)
enableIPv4BIGTCP: true
# -- Enables IPv6 BIG TCP support which increases maximum IPv6 GSO/GRO limits for nodes and pods (BIG TCP is not supported in tunneling mode)
enableIPv6BIGTCP: true

ipv4NativeRoutingCIDR: "{{ cilium_ipv4_native_routing_cidr }}"
ipv6NativeRoutingCIDR: "{{ cilium_ipv6_native_routing_cidr }}"

operator:
  # -- Number of replicas to run for the cilium-operator deployment
  replicas: 1

# we want to specify all the pod CIDR blocks and routes
# autoDirectNodeRoutes: false

# -- Configure L2 announcements
l2announcements:
  # -- Enable L2 announcements
  enabled: true
  # -- If a lease is not renewed for X duration, the current leader is considered dead, a new leader is picked
  leaseDuration: 600s
  # -- The interval at which the leader will renew the lease
  leaseRenewDeadline: 60s
  # -- The timeout between retries if renewal fails
  leaseRetryPeriod: 10s

k8sClientRateLimit:
  qps: 15
  burst: 30

# -- Configure L2 pod announcements
# l2podAnnouncements:
  # -- Enable L2 pod announcements
#  enabled: true
  # -- Interface used for sending Gratuitous ARP pod announcements
#  interface: "eth0"

# extraConfig:
#   enable NDP of pods
#   enable-ipv6-ndp: "true"
#   ipv6-mcast-device: "eth0"
#   ipv6-service-range: "fd69:fd69:face:7::/112"


# -- Specify which network interfaces can run the eBPF datapath. This means
# that a packet sent from a pod to a destination outside the cluster will be
# masqueraded (to an output device IPv4 address), if the output device runs the
# program. When not specified, probing will automatically detect devices.
devices: eth+

# -- Enables experimental support for the detection of new and removed datapath
# devices. When devices change the eBPF datapath is reloaded and services updated.
# If "devices" is set then only those devices, or devices matching a wildcard will
# be considered.
# enableRuntimeDeviceDetection: true

# endpointRoutes:
#  # -- Enable use of per endpoint routes instead of routing via
#  # the cilium_host interface.
#  enabled: true
global:
  nodePort:
    acceleration: best-effort
    mode: hybrid
  bpf:
    natMax: 841429

config:
  bpfMapDynamicSizeRatio: 0.003

tunnelProtocol: geneve
tunnelPort: 6081
routingMode: native #tunnel
MTU: 9000
egressGateway:
  enabled: false

localRedirectPolicy: true

loadBalancer:
  standalone: false
  # maglev = more sticky, random
  algorithm: maglev
  # snat = source nat, dsr = direct server return (can't be used with tunnel: geneve)
  mode: dsr
  
  acceleration: best-effort

  # opt, ipip = lowest overhead but no multicast, geneve=does all the things
  dsrDispatch: opt # geneve

  serviceTopology: true

  l7:
   backend: disabled

gatewayAPI:
  enabled: false
  externalTrafficPolicy: Local
  secretsNamespace:
    create: true
    name: cilium-secrets
    
ingressController:
  enabled: false
  loadbalancerMode: shared
  enforceHttps: false
  default: true
  defaultSecretNamespace: kube-system
  defaultSecretName: default-tls
  secretsNamespace:
    create: true
    name: cilium-secrets
  service:
    allocateLoadBalancerNodePorts: false
    externalTrafficPolicy: Local

clustermesh:
  apiserver:
    service:
      externalTrafficPolicy: Local
      internalTrafficPolicy: Local

l7Proxy: false

envoy:
  enabled: false
  prometheus:
    enabled: true
  securityContext:
    privileged: true
    capabilities:
      keepCapNetBindService: true
      envoy:
        - NET_BIND_SERVICE
        - CAP_NET_ADMIN
        - CAP_BPF
        - NET_ADMIN
        - SYS_ADMIN
        - SYS_RESOURCE
        - PERFMON
        - BPF

nodeinit:
  enabled: true
  securityContext:
    privileged: true


# -- Install Iptables rules to skip netfilter connection tracking on all pod
# traffic. This option is only effective when Cilium is running in direct
# routing and full KPR mode. Moreover, this option cannot be enabled when Cilium
# is running in a managed Kubernetes environment or in a chained CNI setup.
installNoConntrackIptablesRules: true # true # install-no-conntrack-iptables-rules requires the agent to run in direct routing mode.

# Allow docker network to work
daemon:
  enableSourceIPVerification: true